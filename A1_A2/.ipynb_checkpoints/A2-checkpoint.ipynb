{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from math import sqrt\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "class UnlimitedDataWorks:\n",
    "\n",
    "    def __init__(self, deg):\n",
    "        self.exp = []\n",
    "        for i in range(deg+1):\n",
    "            for j in range(deg+1):\n",
    "                if i+j <= deg:\n",
    "                    self.exp.append((i, j))\n",
    "\n",
    "    def train_test_split(self, df):\n",
    "        self.count = 0\n",
    "        self.data = pd.DataFrame([])\n",
    "        print(\"Starting Reality Marble...\")\n",
    "        for col in df.columns:\n",
    "            mx = df[col].max()\n",
    "            mn = df[col].min()\n",
    "            df[col] = (df[col] - mn)/(mx - mn)\n",
    "        for (a, b) in self.exp:\n",
    "            res = ((df[\"lat\"] ** b) * (df[\"lon\"] ** a))\n",
    "            self.data.insert(self.count, \"col\" + str(a) + str(b), res, True)\n",
    "            self.count += 1\n",
    "        \n",
    "        # generate a 70-20-10 split on the data:\n",
    "        X = self.data[:304113]\n",
    "        Y = df[\"alt\"][:304113]\n",
    "        xval = self.data[304113:391088]\n",
    "        yval = df[\"alt\"][304113:391088]\n",
    "        x = self.data[391088:]\n",
    "        y = df[\"alt\"][391088:]   \n",
    "        return (X, Y, xval, yval, x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RegressionModel:\n",
    "\n",
    "    def __init__(self, N, X, Y, x, y, xval, yval):\n",
    "        \"\"\"\n",
    "        X :: training data                  (304113 x 3)\n",
    "        x :: testing data                   (43786 x 3)\n",
    "        Y :: training target values         (304113 x 1)\n",
    "        y :: testing target values          (43786 x 1)\n",
    "        xval :: validation data             (86975 x 3)\n",
    "        yval :: validation training data    (86975 X 1)\n",
    "        \"\"\"\n",
    "        self.N = N\n",
    "        self.X = np.array(X)\n",
    "        self.Y = np.array(Y)\n",
    "        self.x = np.array(x)\n",
    "        self.y = np.array(y)\n",
    "        self.xval = np.array(xval)\n",
    "        self.yval = np.array(yval)\n",
    "        \n",
    "    def score(self, weights):\n",
    "        \"\"\"\n",
    "        the following method helps us find the\n",
    "        R2 (R-squared) error of a given training data\n",
    "        wrt the generated weights\n",
    "        \"\"\"\n",
    "        ss_tot = sum(np.square(np.mean(self.y) - self.y))\n",
    "        ss_res = sum(np.square((self.x @ weights) - self.y))\n",
    "        test_err = (0.5/len(self.x)) * ss_res\n",
    "        print(\"test err =\", test_err)\n",
    "        rmse = sqrt(ss_res/len(self.x))\n",
    "        r2 = (1-(ss_res/ss_tot))\n",
    "        return [r2*100, rmse]\n",
    "\n",
    "    def gradient_descent(self):\n",
    "        \"\"\"\n",
    "        train till error is almost constant\n",
    "        \"\"\"\n",
    "        prev_err, lr = 1e10, 8.5e-7\n",
    "        W = np.ones(self.N)\n",
    "        for _ in range(50001):\n",
    "            diff = ((self.X @ W) - self.Y)\n",
    "            err = 0.5 * (diff @ diff)\n",
    "            grad = (self.X.T @ diff)\n",
    "            if _ % 500 == 0:\n",
    "                print(\"epoch =\", _, \"| err_diff =\", prev_err-err)\n",
    "                print(\"error = \", err/(len(self.X)), \"||\", W)\n",
    "                print(\"score =\", self.score(W), end=\"\\n\\n\")\n",
    "            W -= lr * grad\n",
    "            if abs(prev_err-err) <= 5e-5:\n",
    "                break\n",
    "            prev_err = err\n",
    "        print(err)\n",
    "        print(W, self.score(W), end=\"\\n\\n\")\n",
    "        \n",
    "    def stocastic_gradient_descent(self, epochs):\n",
    "        \"\"\"\n",
    "        train till error is almost constant\n",
    "        \"\"\"\n",
    "        lr = 0.05\n",
    "        W = np.random.randn(self.N)\n",
    "        for _ in range(epochs):\n",
    "            diff = ((self.X @ W) - self.Y)\n",
    "            err = 0.5 * (diff @ diff)\n",
    "            count = np.random.randint(0, len(self.X))\n",
    "            W -= lr * (((self.X[count] @ W) - self.Y[count]) * self.X[count])\n",
    "            if _ % 500 == 0:\n",
    "                print(\"epoch =\", _)\n",
    "                print(\"error =\", err, \"||\", W)\n",
    "                print(\"score =\", self.score(W), end=\"\\n\\n\")\n",
    "        \n",
    "    def gradient_descent_L1_reg(self):\n",
    "        \"\"\"\n",
    "        attempts a L1 regularization on the data\n",
    "        considering 10% of training data as validation data\n",
    "        \"\"\"\n",
    "        W_fin = np.array([])\n",
    "        lr, l1_fin = 8.5e-7, 0\n",
    "        MVLE = 1e10\n",
    "        L1_vals = np.linspace(0.0, 1.0, 10)\n",
    "        sgn = lambda x: (x / abs(x))\n",
    "        for l1 in L1_vals:\n",
    "            prev_err = 1e10\n",
    "            W = np.ones(self.N)\n",
    "            for _ in range(50001):\n",
    "                diff = ((self.X @ W) - self.Y)\n",
    "                err = 0.5 * ((diff @ diff) + l1*sum([abs(w) for w in W]))\n",
    "                if _ % 500 == 0:\n",
    "                    print(\"L1 hyperparamter =\", l1, end=\", \")\n",
    "                    print(\"epoch =\", _, \"| err_diff =\", prev_err-err)\n",
    "                    print(\"error = \", err, \"||\", W)\n",
    "                    print(\"score =\", self.score(W), end=\"\\n\\n\")\n",
    "                sgn_w = np.array([sgn(w) for w in W])\n",
    "                W -= lr * ((self.X.T @ diff) + 0.5*l1*sgn_w)\n",
    "                if abs(prev_err-err) < 0.05:\n",
    "                    break\n",
    "                prev_err = err\n",
    "            VLD = ((self.xval @ W) - self.yval)\n",
    "            VLE = 0.5 * ((VLD @ VLD) + l1*sum([abs(w) for w in W]))\n",
    "            if VLE < MVLE:\n",
    "                W_fin = W\n",
    "                l1_fin = l1\n",
    "                MVLE = VLE\n",
    "        print(MVLE, l1_fin, W_fin)\n",
    "\n",
    "    def gradient_descent_L2_reg(self):\n",
    "        \"\"\"\n",
    "        attempts a L2 regularization on the data\n",
    "        considering 10% of training data as validation data\n",
    "        \"\"\"\n",
    "        W_fin = np.array([])\n",
    "        lr, l2_fin = 8.5e-7, 0\n",
    "        MVLE = 1e10\n",
    "        L2_vals = np.linspace(0.0, 1.0, 10)\n",
    "        for l2 in L2_vals:\n",
    "            prev_err, count = 1e10, 0\n",
    "            W = np.ones(self.N)\n",
    "            for _ in range(50001):\n",
    "                diff = ((self.X @ W) - self.Y)\n",
    "                err = 0.5 * ((diff @ diff) + l2*sum([w*w for w in W]))\n",
    "                if _ % 500 == 0:\n",
    "                    print(\"L2 hyperparamter =\", l2, end=\", \")\n",
    "                    print(\"epoch =\", _, \"| err_diff =\", prev_err-err)\n",
    "                    print(\"error = \", err, \"||\", W)\n",
    "                    print(\"score =\", self.score(W), end=\"\\n\\n\")\n",
    "                W -= lr * ((self.X.T @ diff) + l2*W)\n",
    "                if abs(prev_err-err) < 0.05:\n",
    "                    break\n",
    "                prev_err = err\n",
    "            VLD = ((self.xval @ W) - self.yval)\n",
    "            VLE = 0.5 * ((VLD @ VLD) + l2*(W @ W))\n",
    "            if VLE < MVLE:\n",
    "                W_fin = W\n",
    "                l2_fin = l2\n",
    "                MVLE = VLE\n",
    "        print(MVLE, l2_fin, W_fin)\n",
    "\n",
    "    def fit(self):\n",
    "        \"\"\"\n",
    "        solves for optimal weights using system of\n",
    "        N linear equations; AW = B, hence, W = inv(A)*B\n",
    "        \"\"\"\n",
    "        B = self.X.T @ self.Y\n",
    "        A = self.X.T @ self.X\n",
    "        W = (np.linalg.inv(A)) @ B\n",
    "        print(W, self.score(W))\n",
    "        tmp = ((self.X @ W) - self.Y)\n",
    "        print(\"train_error =\", (0.5/len(self.X)) * (tmp @ tmp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter the Degree of the Polynomial:6\n",
      "Starting Reality Marble...\n",
      "L1 hyperparamter = 0.0, epoch = 0 | err_diff = 9994659975.552462\n",
      "error =  5340024.447539051 || [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1.]\n",
      "test err = 17.47149027045224\n",
      "score = [-207312.57720679554, 5.911258794952601]\n",
      "\n",
      "L1 hyperparamter = 0.0, epoch = 500 | err_diff = 0.624672532348086\n",
      "error =  2469.5595222613547 || [ 0.16917248  0.24250439 -0.01306025 -0.14222513 -0.1651126  -0.12733629\n",
      " -0.06093664  0.02252437 -0.042528   -0.06324759 -0.02328123  0.04925511\n",
      "  0.13367732 -0.05472702 -0.03953276  0.0266414   0.11913734  0.21826061\n",
      " -0.09064732 -0.00586469  0.10614617  0.22311899 -0.10463297  0.02865793\n",
      "  0.16748727 -0.10255315  0.06194428 -0.08878789]\n",
      "test err = 0.008080266875170697\n",
      "score = [4.075213324405569, 0.12712408800200453]\n",
      "\n",
      "L1 hyperparamter = 0.0, epoch = 1000 | err_diff = 0.08046177131382137\n",
      "error =  2369.208029506031 || [ 0.13762516  0.30125674  0.0358271  -0.13233027 -0.18903824 -0.17229313\n",
      " -0.11596593 -0.02347484 -0.03732073 -0.05666408 -0.03321966  0.0234687\n",
      "  0.09768896  0.00190257 -0.00530843  0.03395091  0.10422101  0.18914069\n",
      " -0.02991199  0.01101461  0.09313539  0.19225954 -0.08166935  0.01229788\n",
      "  0.12955248 -0.12386511  0.01391816 -0.14791867]\n",
      "test err = 0.007751914858868499\n",
      "score = [7.973240160013562, 0.12451437554650868]\n",
      "\n",
      "L1 hyperparamter = 0.0, epoch = 1500 | err_diff = 0.05487305446104074\n",
      "error =  2336.5906081546027 || [ 0.14488201  0.29711475  0.0526385  -0.12277944 -0.19239253 -0.18436632\n",
      " -0.13141929 -0.08020723 -0.05127116 -0.04986011 -0.02816966  0.02140509\n",
      "  0.0899669   0.03778436  0.02120348  0.04797124  0.10483261  0.18008449\n",
      "  0.01816602  0.02920756  0.09096514  0.17714383 -0.06029047  0.004647\n",
      "  0.10581092 -0.13688426 -0.01957502 -0.19087568]\n",
      "test err = 0.007644697685320064\n",
      "score = [9.246067488551091, 0.12365029466459079]\n",
      "\n",
      "L1 hyperparamter = 0.1111111111111111, epoch = 0 | err_diff = 9994659973.996906\n",
      "error =  5340026.003094607 || [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1.]\n",
      "test err = 17.47149027045224\n",
      "score = [-207312.57720679554, 5.911258794952601]\n",
      "\n",
      "L1 hyperparamter = 0.1111111111111111, epoch = 500 | err_diff = 0.624679813270177\n",
      "error =  2469.690141551504 || [ 0.1691745   0.24248316 -0.01304617 -0.1422074  -0.16509577 -0.12732582\n",
      " -0.06093737  0.02251172 -0.04251803 -0.06323076 -0.02328445  0.0492354\n",
      "  0.13365897 -0.05471891 -0.03951632  0.02661832  0.11911736  0.21824198\n",
      " -0.09063176 -0.00586486  0.10612615  0.22310049 -0.10461228  0.02863796\n",
      "  0.16746917 -0.10253701  0.0619267  -0.08877906]\n",
      "test err = 0.008080206535963894\n",
      "score = [4.075929640540943, 0.12712361335301867]\n",
      "\n",
      "L1 hyperparamter = 0.1111111111111111, epoch = 1000 | err_diff = 0.08044519588383992\n",
      "error =  2369.333096014459 || [ 0.1376355   0.30121648  0.0358206  -0.13229499 -0.18900379 -0.17226474\n",
      " -0.11594856 -0.0235026  -0.0372942  -0.05662721 -0.03320065  0.02342498\n",
      "  0.09764678  0.00191699 -0.00527444  0.03390333  0.10417897  0.18910083\n",
      " -0.02988453  0.011008    0.0930935   0.19222103 -0.08163195  0.01225471\n",
      "  0.12951455 -0.12382789  0.01387997 -0.14788518]\n",
      "test err = 0.0077518681239035344\n",
      "score = [7.973794973562887, 0.12451400020803713]\n",
      "\n",
      "L1 hyperparamter = 0.1111111111111111, epoch = 1500 | err_diff = 0.054821888508286065\n",
      "error =  2336.7344706131307 || [ 0.14489373  0.29706666  0.05261049 -0.12272508 -0.19234243 -0.18432442\n",
      " -0.13138992 -0.08022267 -0.05122254 -0.04979855 -0.02812565  0.02133825\n",
      "  0.08990021  0.03776418  0.02122324  0.04790497  0.10477281  0.18002618\n",
      "  0.01819251  0.02918149  0.09090747  0.17709014 -0.06023015  0.00458728\n",
      "  0.10575907 -0.13681995 -0.01959921 -0.19081181]\n",
      "test err = 0.007644688020791994\n",
      "score = [9.246182220874621, 0.12365021650439594]\n",
      "\n",
      "L1 hyperparamter = 0.2222222222222222, epoch = 0 | err_diff = 9994659972.441349\n",
      "error =  5340027.558650162 || [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1.]\n",
      "test err = 17.47149027045224\n",
      "score = [-207312.57720679554, 5.911258794952601]\n",
      "\n",
      "L1 hyperparamter = 0.2222222222222222, epoch = 500 | err_diff = 0.6246872096089646\n",
      "error =  2469.8207195350446 || [ 0.16917651  0.24246194 -0.01303208 -0.14218967 -0.16507894 -0.12731535\n",
      " -0.06093809  0.02249906 -0.04250805 -0.06321392 -0.02328767  0.04921568\n",
      "  0.13364061 -0.05471081 -0.03949989  0.02659524  0.11909737  0.21822336\n",
      " -0.09061619 -0.00586504  0.10610614  0.223082   -0.10459159  0.02861799\n",
      "  0.16745106 -0.10252087  0.06190912 -0.08877022]\n",
      "test err = 0.00808014620460838\n",
      "score = [4.076645863469819, 0.12712313876402187]\n",
      "\n",
      "L1 hyperparamter = 0.2222222222222222, epoch = 1000 | err_diff = 0.08042873536760453\n",
      "error =  2369.4580905157945 || [ 0.13764584  0.30117621  0.0358141  -0.13225972 -0.18896934 -0.17223634\n",
      " -0.11593118 -0.02353035 -0.03726766 -0.05659035 -0.03318163  0.02338127\n",
      "  0.09760461  0.00193143 -0.00524043  0.03385576  0.10413693  0.18906097\n",
      " -0.02985705  0.01100122  0.09305163  0.19218252 -0.08159454  0.01221157\n",
      "  0.12947663 -0.12379067  0.01384179 -0.14785167]\n",
      "test err = 0.007751821438997007\n",
      "score = [7.974349192844111, 0.12451362527046594]\n",
      "\n",
      "L1 hyperparamter = 0.2222222222222222, epoch = 1500 | err_diff = 0.05477085040456586\n",
      "error =  2336.8782516467318 || [ 0.14490544  0.29701857  0.05258249 -0.1226707  -0.19229234 -0.18428252\n",
      " -0.13136055 -0.08023809 -0.05117389 -0.04973698 -0.02808164  0.02127143\n",
      "  0.08983353  0.03774404  0.02124283  0.04783872  0.10471302  0.17996787\n",
      "  0.01821902  0.02915524  0.09084982  0.17703646 -0.06016983  0.00452756\n",
      "  0.10570723 -0.13675564 -0.01962321 -0.19074795]\n",
      "test err = 0.007644678485916612\n",
      "score = [9.246295414027927, 0.1236501393926963]\n",
      "\n",
      "L1 hyperparamter = 0.3333333333333333, epoch = 0 | err_diff = 9994659970.885794\n",
      "error =  5340029.114205718 || [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1.]\n",
      "test err = 17.47149027045224\n",
      "score = [-207312.57720679554, 5.911258794952601]\n",
      "\n",
      "L1 hyperparamter = 0.3333333333333333, epoch = 500 | err_diff = 0.6246950004497194\n",
      "error =  2469.9512967067776 || [ 0.16917853  0.24244072 -0.01301801 -0.14217198 -0.16506215 -0.12730492\n",
      " -0.06093858  0.02248642 -0.04249807 -0.06319709 -0.02329091  0.04919594\n",
      "  0.13362222 -0.05470269 -0.03948345  0.02657216  0.11907738  0.21820472\n",
      " -0.09060062 -0.00586521  0.10608613  0.2230635  -0.10457089  0.02859802\n",
      "  0.16743296 -0.10250473  0.06189154 -0.08876137]\n",
      "test err = 0.008080086013215318\n",
      "score = [4.077360424836229, 0.12712266527425642]\n",
      "\n",
      "L1 hyperparamter = 0.3333333333333333, epoch = 1000 | err_diff = 0.0804124478072481\n",
      "error =  2369.5830722988385 || [ 0.13765615  0.30113597  0.03580761 -0.13222446 -0.18893493 -0.172208\n",
      " -0.11591359 -0.0235579  -0.03724115 -0.05655349 -0.03316263  0.02333752\n",
      "  0.09756241  0.00194554 -0.00520643  0.03380819  0.10409488  0.1890211\n",
      " -0.02982957  0.01099454  0.09300976  0.19214402 -0.08155711  0.01216843\n",
      "  0.12943873 -0.12375342  0.01380363 -0.14781814]\n",
      "test err = 0.0077517750031351924\n",
      "score = [7.974900455594147, 0.12451325233191199]\n",
      "\n",
      "L1 hyperparamter = 0.3333333333333333, epoch = 1500 | err_diff = 0.05471995701554988\n",
      "error =  2337.0219731705115 || [ 0.14491712  0.29697052  0.0525545  -0.12261636 -0.19224229 -0.18424069\n",
      " -0.13133099 -0.08025331 -0.05112525 -0.04967541 -0.02803763  0.02120457\n",
      "  0.0897668   0.03772362  0.02126225  0.04777248  0.10465324  0.17990955\n",
      "  0.01824556  0.02912913  0.09079219  0.17698279 -0.06010946  0.00446788\n",
      "  0.10565541 -0.13669129 -0.01964728 -0.19068405]\n",
      "test err = 0.007644669152770424\n",
      "score = [9.246406212355618, 0.12365006391240098]\n",
      "\n",
      "L1 hyperparamter = 0.4444444444444444, epoch = 0 | err_diff = 9994659969.330238\n",
      "error =  5340030.669761273 || [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1.]\n",
      "test err = 17.47149027045224\n",
      "score = [-207312.57720679554, 5.911258794952601]\n",
      "\n",
      "L1 hyperparamter = 0.4444444444444444, epoch = 500 | err_diff = 0.624702720625919\n",
      "error =  2470.081805560849 || [ 0.16918055  0.2424195  -0.01300394 -0.14215426 -0.16504533 -0.12729447\n",
      " -0.06093923  0.02247377 -0.0424881  -0.06318025 -0.02329414  0.04917622\n",
      "  0.13360386 -0.05469459 -0.03946702  0.02654908  0.11905739  0.21818609\n",
      " -0.09058506 -0.00586539  0.10606612  0.223045   -0.10455019  0.02857805\n",
      "  0.16741485 -0.10248858  0.06187397 -0.08875253]\n",
      "test err = 0.00808002574159737\n",
      "score = [4.078075938591342, 0.12712219115164253]\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "L1 hyperparamter = 0.4444444444444444, epoch = 1000 | err_diff = 0.08039624554294278\n",
      "error =  2369.707938518906 || [ 0.13766648  0.30109583  0.03580084 -0.13218912 -0.18890045 -0.1721796\n",
      " -0.11589613 -0.0235856  -0.03721459 -0.05651661 -0.03314361  0.0232938\n",
      "  0.09752023  0.00195986 -0.00517242  0.03376062  0.10405284  0.18898124\n",
      " -0.0298021   0.01098785  0.09296788  0.19210551 -0.0815197   0.01212529\n",
      "  0.12940081 -0.12371619  0.01376544 -0.14778463]\n",
      "test err = 0.007751728468036895\n",
      "score = [7.975452896428836, 0.12451287859524328]\n",
      "\n",
      "L1 hyperparamter = 0.4444444444444444, epoch = 1500 | err_diff = 0.0546691827921677\n",
      "error =  2337.165614200327 || [ 0.1449288   0.29692258  0.05252623 -0.12256192 -0.19219218 -0.18419881\n",
      " -0.13130156 -0.08026862 -0.05107655 -0.04961381 -0.02799362  0.02113773\n",
      "  0.08970009  0.03770341  0.02128187  0.04770623  0.10459345  0.17985123\n",
      "  0.01827173  0.02910299  0.09073454  0.17692909 -0.06004912  0.00440817\n",
      "  0.10560356 -0.13662698 -0.019671   -0.19062019]\n",
      "test err = 0.007644659946050905\n",
      "score = [9.246515509810704, 0.12364998945451557]\n",
      "\n",
      "L1 hyperparamter = 0.5555555555555556, epoch = 0 | err_diff = 9994659967.774683\n",
      "error =  5340032.225316829 || [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1.]\n",
      "test err = 17.47149027045224\n",
      "score = [-207312.57720679554, 5.911258794952601]\n",
      "\n",
      "L1 hyperparamter = 0.5555555555555556, epoch = 500 | err_diff = 0.6247105562015349\n",
      "error =  2470.212273101054 || [ 0.16918257  0.24239827 -0.01298986 -0.14213654 -0.16502852 -0.12728401\n",
      " -0.06093987  0.02246111 -0.04247812 -0.06316342 -0.02329737  0.04915649\n",
      "  0.13358549 -0.05468648 -0.03945058  0.026526    0.11903741  0.21816746\n",
      " -0.09056949 -0.00586556  0.1060461   0.22302651 -0.1045295   0.02855807\n",
      "  0.16739675 -0.10247244  0.06185639 -0.08874369]\n",
      "test err = 0.008079965477829906\n",
      "score = [4.078791359149547, 0.12712171708901596]\n",
      "\n",
      "L1 hyperparamter = 0.5555555555555556, epoch = 1000 | err_diff = 0.08038013961413526\n",
      "error =  2369.8327156652035 || [ 0.13767681  0.3010556   0.03579428 -0.13215383 -0.188866   -0.17215122\n",
      " -0.11587868 -0.02361329 -0.03718806 -0.05647974 -0.03312459  0.02325008\n",
      "  0.09747804  0.00197418 -0.00513842  0.03371305  0.1040108   0.18894138\n",
      " -0.02977463  0.01098116  0.092926    0.192067   -0.08148229  0.01208214\n",
      "  0.12936289 -0.12367897  0.01372727 -0.14775112]\n",
      "test err = 0.0077516819279016816\n",
      "score = [7.976005397059227, 0.12451250481699966]\n",
      "\n",
      "L1 hyperparamter = 0.5555555555555556, epoch = 1500 | err_diff = 0.0546185256107492\n",
      "error =  2337.3091469605406 || [ 0.14494048  0.29687455  0.05249818 -0.12250754 -0.19214208 -0.18415693\n",
      " -0.13127213 -0.0802839  -0.05102786 -0.04955221 -0.02794959  0.0210709\n",
      "  0.08963339  0.03768322  0.02130102  0.04763999  0.10453366  0.17979291\n",
      "  0.01829816  0.02907685  0.09067688  0.1768754  -0.0599888   0.00434845\n",
      "  0.1055517  -0.13656269 -0.01969456 -0.19055636]\n",
      "test err = 0.007644650785033269\n",
      "score = [9.246624264716452, 0.12364991536619238]\n",
      "\n",
      "L1 hyperparamter = 0.6666666666666666, epoch = 0 | err_diff = 9994659966.219128\n",
      "error =  5340033.780872384 || [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1.]\n",
      "test err = 17.47149027045224\n",
      "score = [-207312.57720679554, 5.911258794952601]\n",
      "\n",
      "L1 hyperparamter = 0.6666666666666666, epoch = 500 | err_diff = 0.624718507183843\n",
      "error =  2470.34269932739 || [ 0.16918459  0.24237705 -0.01297578 -0.14211882 -0.1650117  -0.12727356\n",
      " -0.06094052  0.02244846 -0.04246814 -0.06314658 -0.02330059  0.04913677\n",
      "  0.13356712 -0.05467837 -0.03943414  0.02650292  0.11901742  0.21814883\n",
      " -0.09055393 -0.00586574  0.10602609  0.22300801 -0.1045088   0.0285381\n",
      "  0.16737865 -0.1024563   0.06183881 -0.08873485]\n",
      "test err = 0.008079905221912846\n",
      "score = [4.07950668651178, 0.12712124308637676]\n",
      "\n",
      "L1 hyperparamter = 0.6666666666666666, epoch = 1000 | err_diff = 0.08036415791002582\n",
      "error =  2369.9574366217103 || [ 0.13768713  0.30101537  0.03578771 -0.13211854 -0.18883155 -0.17212284\n",
      " -0.11586123 -0.02364097 -0.0371615  -0.05644285 -0.03310557  0.02320636\n",
      "  0.09743587  0.00198853 -0.00510438  0.0336655   0.10396878  0.18890153\n",
      " -0.02974711  0.01097394  0.09288416  0.19202852 -0.08144483  0.01203903\n",
      "  0.129325   -0.12364169  0.01368912 -0.14771756]\n",
      "test err = 0.007751635491862287\n",
      "score = [7.976556661917411, 0.1245121318736635]\n",
      "\n",
      "L1 hyperparamter = 0.6666666666666666, epoch = 1500 | err_diff = 0.05456801500895381\n",
      "error =  2337.4526268607733 || [ 0.14495215  0.29682651  0.05247012 -0.12245316 -0.19209201 -0.18411507\n",
      " -0.13124272 -0.08029913 -0.0509791  -0.04949055 -0.02790553  0.02100408\n",
      "  0.0895667   0.03766316  0.02132009  0.04757383  0.10447393  0.17973463\n",
      "  0.0183242   0.02905026  0.09061931  0.17682176 -0.05992831  0.00428884\n",
      "  0.10549993 -0.13649825 -0.01971839 -0.19049239]\n",
      "test err = 0.007644641847901183\n",
      "score = [9.246730361767707, 0.12364984308846641]\n",
      "\n",
      "L1 hyperparamter = 0.7777777777777777, epoch = 0 | err_diff = 9994659964.663572\n",
      "error =  5340035.33642794 || [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1.]\n",
      "test err = 17.47149027045224\n",
      "score = [-207312.57720679554, 5.911258794952601]\n",
      "\n",
      "L1 hyperparamter = 0.7777777777777777, epoch = 500 | err_diff = 0.6247265735687506\n",
      "error =  2470.473084239858 || [ 0.1691866   0.24235583 -0.0129617  -0.14210111 -0.16499488 -0.1272631\n",
      " -0.06094116  0.02243581 -0.04245816 -0.06312975 -0.02330382  0.04911705\n",
      "  0.13354876 -0.05467026 -0.03941771  0.02647984  0.11899743  0.2181302\n",
      " -0.09053836 -0.00586591  0.10600608  0.22298951 -0.10448811  0.02851813\n",
      "  0.16736054 -0.10244016  0.06182124 -0.08872601]\n",
      "test err = 0.00807984497384606\n",
      "score = [4.080221920679583, 0.12712076914372458]\n",
      "\n",
      "L1 hyperparamter = 0.7777777777777777, epoch = 1000 | err_diff = 0.08034833590227208\n",
      "error =  2370.0821477259665 || [ 0.13769739  0.30097513  0.03578116 -0.13208323 -0.18879708 -0.17209444\n",
      " -0.11584376 -0.02366829 -0.03713508 -0.05640603 -0.03308656  0.02316264\n",
      "  0.09739369  0.0020027  -0.00507043  0.03361791  0.10392674  0.18886168\n",
      " -0.0297197   0.01096715  0.09284229  0.19199002 -0.08140744  0.01199589\n",
      "  0.1292871  -0.12360445  0.01365097 -0.14768402]\n",
      "test err = 0.007751589310102836\n",
      "score = [7.977104908094423, 0.1245117609714266]\n",
      "\n",
      "L1 hyperparamter = 0.7777777777777777, epoch = 1500 | err_diff = 0.05451763058454162\n",
      "error =  2337.5960200991362 || [ 0.14496379  0.29677849  0.05244208 -0.12239875 -0.1920419  -0.18407318\n",
      " -0.13121328 -0.08031416 -0.05093055 -0.04942902 -0.02786153  0.02093724\n",
      "  0.0895      0.03764277  0.02133946  0.04750756  0.10441413  0.17967632\n",
      "  0.01835047  0.02902401  0.09056166  0.17676808 -0.05986801  0.00422912\n",
      "  0.10544808 -0.13643395 -0.01974164 -0.19042854]\n",
      "test err = 0.007644633021741287\n",
      "score = [9.246835141414012, 0.12364977170817006]\n",
      "\n",
      "L1 hyperparamter = 0.8888888888888888, epoch = 0 | err_diff = 9994659963.108017\n",
      "error =  5340036.891983495 || [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1.]\n",
      "test err = 17.47149027045224\n",
      "score = [-207312.57720679554, 5.911258794952601]\n",
      "\n",
      "L1 hyperparamter = 0.8888888888888888, epoch = 500 | err_diff = 0.6247348056335795\n",
      "error =  2470.6033949039684 || [ 0.16918863  0.24233461 -0.01294762 -0.14208339 -0.16497806 -0.12725264\n",
      " -0.0609418   0.02242315 -0.04244821 -0.06311294 -0.02330707  0.04909731\n",
      "  0.13353038 -0.05466221 -0.03940131  0.02645672  0.11897742  0.21811155\n",
      " -0.09052286 -0.00586538  0.10598603  0.22297099 -0.10446748  0.02849811\n",
      "  0.1673424  -0.10242408  0.06180361 -0.08871723]\n",
      "test err = 0.008079784623324029\n",
      "score = [4.080938371143528, 0.1271202943933346]\n",
      "\n",
      "L1 hyperparamter = 0.8888888888888888, epoch = 1000 | err_diff = 0.08033263784500377\n",
      "error =  2370.206743618734 || [ 0.13770773  0.30093493  0.03577462 -0.13204793 -0.18876262 -0.17206604\n",
      " -0.11582629 -0.02369582 -0.03710852 -0.05636915 -0.03306754  0.02311892\n",
      "  0.09735151  0.00201629 -0.00503642  0.03357034  0.10388469  0.18882181\n",
      " -0.02969222  0.01096112  0.0928004   0.19195151 -0.08137002  0.01195274\n",
      "  0.12924918 -0.12356722  0.01361279 -0.14765051]\n",
      "test err = 0.007751543041211198\n",
      "score = [7.9776541886601215, 0.12451138936829191]\n",
      "\n",
      "L1 hyperparamter = 0.8888888888888888, epoch = 1500 | err_diff = 0.05446737131023838\n",
      "error =  2337.7393285547055 || [ 0.14497543  0.29673048  0.05241403 -0.12234437 -0.19199181 -0.1840313\n",
      " -0.13118385 -0.0803291  -0.05088175 -0.04936738 -0.0278175   0.0208704\n",
      "  0.08943329  0.03762199  0.02135819  0.04744132  0.10435432  0.17961797\n",
      "  0.01837689  0.02899853  0.09050397  0.17671434 -0.05980768  0.00416936\n",
      "  0.10539617 -0.1363697  -0.01976479 -0.19036479]\n",
      "test err = 0.007644624313759069\n",
      "score = [9.246938518115488, 0.12364970128357827]\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "L1 hyperparamter = 1.0, epoch = 0 | err_diff = 9994659961.552462\n",
      "error =  5340038.447539051 || [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1.]\n",
      "test err = 17.47149027045224\n",
      "score = [-207312.57720679554, 5.911258794952601]\n",
      "\n",
      "L1 hyperparamter = 1.0, epoch = 500 | err_diff = 0.6247431091060207\n",
      "error =  2470.733693032539 || [ 0.16919065  0.24231339 -0.01293354 -0.14206567 -0.16496125 -0.12724218\n",
      " -0.06094245  0.02241049 -0.04243824 -0.0630961  -0.0233103   0.04907758\n",
      "  0.13351201 -0.05465411 -0.03938488  0.02643364  0.11895743  0.21809292\n",
      " -0.0905073  -0.00586547  0.10596601  0.22295249 -0.10444679  0.02847813\n",
      "  0.16732429 -0.10240795  0.06178603 -0.0887084 ]\n",
      "test err = 0.008079724377165514\n",
      "score = [4.08165358265733, 0.127119820462157]\n",
      "\n",
      "L1 hyperparamter = 1.0, epoch = 1000 | err_diff = 0.08031699199000286\n",
      "error =  2370.331222594399 || [ 0.13771805  0.3008947   0.03576806 -0.13201263 -0.18872817 -0.17203766\n",
      " -0.11580884 -0.02372344 -0.037082   -0.05633229 -0.03304853  0.0230752\n",
      "  0.09730933  0.00203051 -0.00500242  0.03352277  0.10384265  0.18878195\n",
      " -0.02966475  0.01095443  0.09275853  0.19191301 -0.08133261  0.0119096\n",
      "  0.12921127 -0.12352998  0.01357461 -0.14761699]\n",
      "test err = 0.007751496667582596\n",
      "score = [7.978204712609349, 0.12451101692286186]\n",
      "\n",
      "L1 hyperparamter = 1.0, epoch = 1500 | err_diff = 0.05441723772082696\n",
      "error =  2337.8825497260054 || [ 0.14498707  0.29668244  0.05238597 -0.12228999 -0.19194174 -0.18398945\n",
      " -0.13115445 -0.08034417 -0.05083295 -0.04930571 -0.02777344  0.02080358\n",
      "  0.08936659  0.03760191  0.02137682  0.04737517  0.10429459  0.17955969\n",
      "  0.01840259  0.02897252  0.0904464   0.1766607  -0.05974717  0.00410976\n",
      "  0.10534439 -0.13630526 -0.01978844 -0.19030083]\n",
      "test err = 0.007644615716013679\n",
      "score = [9.247040586141841, 0.1236496317504721]\n",
      "\n",
      "672.7165138733151 0.0 [ 0.14809843  0.29345411  0.05661954 -0.11991435 -0.19276645 -0.18694535\n",
      " -0.13471817 -0.09638139 -0.05607899 -0.04769297 -0.02600839  0.0217021\n",
      "  0.08870858  0.04808588  0.02879195  0.05234979  0.10549288  0.17799193\n",
      "  0.0321116   0.0345202   0.0904906   0.17295142 -0.05413806  0.00236557\n",
      "  0.09888531 -0.14080285 -0.02945836 -0.20352262]\n"
     ]
    }
   ],
   "source": [
    "columns = [\"junk\", \"lat\", \"lon\", \"alt\"]\n",
    "raw_df = pd.read_csv(\"3D_spatial_network.txt\", sep=',', header=None,\n",
    "                     names=columns).drop(\"junk\", 1).sample(frac=1)\n",
    "\n",
    "deg = input(\"Enter the Degree of the Polynomial:\")\n",
    "pre_processor = UnlimitedDataWorks(deg=int(deg))\n",
    "X_train, Y_train, x_val, y_val, x_test, y_test = pre_processor.train_test_split(raw_df)\n",
    "\n",
    "model = RegressionModel(N=pre_processor.count,\n",
    "                        X=X_train,\n",
    "                        Y=Y_train,\n",
    "                        x=x_test,\n",
    "                        y=y_test,\n",
    "                        xval=x_val,\n",
    "                        yval=y_val)\n",
    "\n",
    "# model.fit()\n",
    "# model.gradient_descent()\n",
    "# model.stocastic_gradient_descent(50000)\n",
    "model.gradient_descent_L1_reg()\n",
    "# model.gradient_descent_L2_reg()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
